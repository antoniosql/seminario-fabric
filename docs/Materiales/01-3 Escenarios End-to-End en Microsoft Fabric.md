## **1. ETL con Microsoft Fabric: Uso de Dataflows Gen2 y Pipelines**

### üîπ **Introducci√≥n a los procesos ETL en Fabric**

En Microsoft Fabric, los procesos ETL (Extract, Transform, Load) pueden realizarse a trav√©s de tres  herramientas principales:

1. **Dataflows Gen2** (para transformaciones sin c√≥digo o de bajo c√≥digo).
2. **Pipelines en Data Factory** (para cargas y orquestaci√≥n m√°s avanzadas).
3. **Notebooks** de PySpark, con c√≥digo completamente personalizable

Ambas herramientas est√°n dise√±adas para simplificar la ingesta y transformaci√≥n de datos, integr√°ndose con **OneLake, Lakehouses y Data Warehouses**.

### üîπ **Dataflows Gen2: Transformaciones sin c√≥digo**

Los **Dataflows Gen2** permiten la creaci√≥n de procesos ETL en un entorno visual, facilitando:  
‚úÖ Conexi√≥n con m√∫ltiples fuentes de datos, incluyendo **OneLake, SQL, SaaS y APIs**.  
‚úÖ Uso de **Power Query** para transformaciones sin necesidad de programaci√≥n.  
‚úÖ **Automatizaci√≥n de cargas peri√≥dicas** con programaci√≥n de actualizaciones.

üìå **Ventajas de Dataflows Gen2**

- Ideal para **usuarios de negocio y analistas de datos** que necesitan transformar datos sin escribir c√≥digo.
- Se ejecuta directamente en **Microsoft Fabric**, evitando la necesidad de exportaciones a otros servicios.
- Puede alimentar **modelos sem√°nticos de Power BI** sin pasos adicionales.

Una de las grandes diferencias entre los Dataflows tradicionales y los Dataflows de Generaci√≥n 2, es que estos √∫ltimos pueden almacenar el resultado de sus ejecuciones en diferentes destinos
![[Dataflow Gen2 Destinos.png]]
### üîπ **Pipelines de Data Factory: Orquestaci√≥n avanzada**

Los **Pipelines en Data Factory** dentro de Fabric proporcionan una soluci√≥n **m√°s avanzada y escalable** para la integraci√≥n de datos:  
‚úÖ Permite la creaci√≥n de **flujos de trabajo de datos complejos** con m√∫ltiples pasos.  
‚úÖ Integraci√≥n con **Azure Data Factory** para reutilizaci√≥n de flujos existentes.  
‚úÖ Soporta **activadores y ejecuci√≥n basada en eventos**, lo que facilita la automatizaci√≥n de cargas.

üìå **Diferencias entre Dataflows Gen2 y Pipelines**

|**Caracter√≠stica**|**Dataflows Gen2**|**Pipelines en Data Factory**|
|---|---|---|
|**Orientaci√≥n**|Usuarios de negocio, analistas|Ingenieros de datos, arquitectos|
|**C√≥digo necesario**|No-Code/Low-Code (Power Query)|Requiere configuraci√≥n avanzada|
|**Escalabilidad**|Adecuado para vol√∫menes moderados de datos|Ideal para cargas de datos masivas|
|**Automatizaci√≥n**|Programaciones b√°sicas|Orquestaci√≥n avanzada con dependencias|

üîπ **Ejemplo pr√°ctico**: Un **Dataflow Gen2** puede usarse para transformar datos de ventas en bruto en **OneLake**, mientras que un **Pipeline** se encargar√° de la carga incremental en un **Data Warehouse**‚Äãfabric-fundamentals.
### üîπ **Notebooks de PySpark**

Para cargas de trabajo que requieran de la flexibilidad que proporciona un lenguaje de programaci√≥n como Python, escalando a trav√©s de Apache Spark, tenemos la posibilidad de escribir todos nuestros procesos utilizando Notebooks de PySpark. Son una opci√≥n flexible, porque adem√°s de tener a nuestra disposici√≥n una gran cantidad de librer√≠as para procesado, y toda la potencia de los cl√∫steres de Apache Spark, estos Notebooks son la opci√≥n que m√°s nos a√≠sla de Microsoft Fabric. Si por ejemplo, el d√≠a de ma√±ana queremos migrar alguna carga de trabajo a Databricks, podr√≠amos reutilizar una gran cantidad de ese c√≥digo, algo que no es posible si utilizamos Dataflows y muy complicado con los Pipelines de Data Factory. 

---

## **2. Almacenamiento y An√°lisis: Integraci√≥n con Lakehouses y Data Warehouses**

### üîπ **Lakehouses en Microsoft Fabric**

El **Lakehouse** es una combinaci√≥n de **Data Lake y Data Warehouse**, permitiendo almacenar y analizar datos en un √∫nico entorno.

‚úÖ Basado en el formato **Delta Lake**, lo que permite transacciones ACID y versionado de datos.  
‚úÖ Integrado con **OneLake**, lo que elimina la duplicaci√≥n de datos.  
‚úÖ Soporta acceso desde **T-SQL y Spark**, facilitando la colaboraci√≥n entre equipos de datos.

üìå **Cu√°ndo usar un Lakehouse**

- Si se necesitan **tanto an√°lisis estructurados como semiestructurados** en un mismo entorno.
- Cuando los **cient√≠ficos de datos y analistas** deben trabajar sobre el mismo conjunto de datos.
- Para **procesamiento en batch y en tiempo real** dentro de Fabric‚Äã.

### üîπ **Data Warehouses en Microsoft Fabric**

Un **Data Warehouse en Fabric** es una soluci√≥n de almacenamiento estructurado, optimizada para consultas SQL y an√°lisis de datos transaccionales.

‚úÖ Usa **T-SQL nativo**, facilitando la migraci√≥n desde bases de datos SQL tradicionales.  
‚úÖ Soporta consultas de alto rendimiento y escalabilidad autom√°tica.  
‚úÖ Permite la integraci√≥n con **Power BI y otros servicios de Fabric**.

üìå **Cu√°ndo usar un Data Warehouse**

- Si los datos son **estructurados** y requieren consultas SQL optimizadas.
- Cuando se necesita **compatibilidad con herramientas de an√°lisis basadas en SQL**.
- Si los datos deben **mantenerse en un formato relacional con transacciones ACID**.

üîπ **Ejemplo pr√°ctico**: Un **Lakehouse** puede almacenar grandes vol√∫menes de datos en bruto de sensores IoT, mientras que un **Data Warehouse** almacena versiones agregadas para an√°lisis financieros‚Äã.

Otro criterio de selecci√≥n, est√° relacionado con los conocimientos que tengan los equipos para el desarrollo y mantenimiento de la soluci√≥n. Teniendo en cuenta que el almacenamiento se realiza en Onelake y en formato Delta, es relevante el hecho de que los equipos deban de conocer o familiarizarse con Notebooks y PySpark, o por el contrario conocimientos de T-SQL. 

---

## **3. Caso pr√°ctico: Dise√±o de una soluci√≥n de datos escalable**

### üîπ **Escenario realista: Plataforma de An√°lisis de Ventas**

Se dise√±ar√° una soluci√≥n que permita a una empresa de retail analizar sus ventas y optimizar la distribuci√≥n de productos en sus tiendas.

#### **Requerimientos**

1Ô∏è‚É£ **Ingesta de datos de ventas en tiempo real** desde m√∫ltiples sistemas POS.  
2Ô∏è‚É£ **Procesamiento de datos con Dataflows Gen2** para limpieza y transformaci√≥n.  
3Ô∏è‚É£ **Carga en OneLake** utilizando Pipelines de Data Factory.  
4Ô∏è‚É£ **Uso de un Lakehouse** para almacenar datos hist√≥ricos en bruto.  
5Ô∏è‚É£ **Creaci√≥n de un Data Warehouse** para consultas SQL optimizadas.  
6Ô∏è‚É£ **Modelado en Power BI** para generaci√≥n de informes interactivos.

#### **Arquitectura de la soluci√≥n**

4. **Extracci√≥n de datos** desde bases de datos SQL y APIs de terceros.
5. **Transformaci√≥n en Dataflows Gen2** para limpieza y agregaciones.
6. **Carga en OneLake y procesamiento con Spark en un Lakehouse**.
7. **Creaci√≥n de un modelo anal√≠tico en un Data Warehouse** para consultas SQL.
8. **Publicaci√≥n en Power BI** con dashboards en tiempo real.

üîπ **Beneficios de esta arquitectura:**  
‚úÖ **Eficiencia y escalabilidad:** Fabric maneja grandes vol√∫menes de datos sin sobrecargar sistemas transaccionales.  
‚úÖ **An√°lisis en tiempo real:** Las decisiones pueden tomarse con informaci√≥n actualizada al minuto.  
‚úÖ **Reducci√≥n de costos:** No se requiere infraestructura dedicada, todo funciona en la nube con escalabilidad autom√°tica.

üìå **Resultado esperado:**  
Con esta soluci√≥n, los equipos de ventas y finanzas pueden acceder a datos en tiempo real sobre el desempe√±o de productos en distintas ubicaciones, optimizando la cadena de suministro y aumentando la rentabilidad‚Äã.

---
## **4. Escenarios y Arquitecturas**

### üîπ **El m√°s sencillo**
Imaginemos que queremos actualizar nuestra arquitectura Power BI, porque tenemos m√°s necesidades de carga de datos, o simplemente queremos comenzar a analizar datos no estructuras de un modo m√°s √°gil. En un escenario de este estilo, podr√≠amos tener:
- Un espacio de trabajo con una capacidad F2 o F4, iniciada √∫nicamente en los momentos en los que necesitamos realizar la carga y procesamiento de los datos
- Nuestros procesos de ingenier√≠a de datos para limpieza y dem√°s tareas que dejen los datos listos en nuestro warehouse
- Otro espacio de trabajo en el que tengamos los modelos sem√°nticos de Power BI, en modo import, y sus correspondientes informes
De esta forma, podemos disponer de las capacidades de Fabric de un modo econ√≥mico, al estar pagando √∫nicamente por el tiempo en el que realizamos las cargas de datos. Al tener los modelos sem√°nticos en Modo Import, no necesitamos que la capacidad de Fabric est√© iniciada cuando los usuarios acceden a los informes. 

### üîπ **Monol√≠tico**
En un escenario de este tipo, disponemos √∫nicamente de una capacidad que est√° asignada a un √∫nico espacio de trabajo de Fabric, para dar soporte, por ejemplo, a lo comentado en la secci√≥n anterior. 
![[Despliegue Monolitico.png]]

### üîπ **Capacidad Compartida**
Disponemos de una √∫nica capacidad de Fabric que es compartida por diferentes espacios de trabajo, para dar soporte a las cargas que se ejecuten en dichos espacios de trabajo

![[Despliegue Compartido.png]]

### üîπ **Escalado**
Para escenarios que requieren de recursos dedicados, o que sea necesario escalar los recursos, podemos disponer de diferentes capacidades asignadas a distintos espacios de trabajo de Fabric

![[Despliegue Escalado.png]]

---

## **5. Conclusi√≥n y Preguntas Clave**

‚úÖ **Microsoft Fabric permite dise√±ar soluciones end-to-end combinando ETL, almacenamiento y an√°lisis en una √∫nica plataforma.**  
‚úÖ **Dataflows Gen2 y Pipelines facilitan la ingesta y transformaci√≥n de datos en Fabric.**  
‚úÖ **El uso combinado de Lakehouses y Data Warehouses proporciona una arquitectura flexible y escalable.**  
‚úÖ **Un dise√±o bien estructurado en Fabric mejora la eficiencia, reduce costes y habilita an√°lisis avanzados.**

### **Preguntas de reflexi√≥n para la sesi√≥n**

1. ¬øCu√°ndo deber√≠as utilizar Dataflows Gen2 en lugar de Pipelines en Data Factory?
2. ¬øEn qu√© casos es preferible usar un Lakehouse en vez de un Data Warehouse?
3. ¬øC√≥mo asegurar√≠as la escalabilidad de una soluci√≥n de datos en Fabric para grandes vol√∫menes de datos?