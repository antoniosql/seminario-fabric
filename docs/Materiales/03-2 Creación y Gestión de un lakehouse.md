## **1. Definici√≥n y ventajas de un Lakehouse frente a un Data Warehouse tradicional**

### üîπ **¬øQu√© es un Lakehouse?**

Un **Lakehouse** en Microsoft Fabric es una arquitectura h√≠brida que combina lo mejor de un **Data Lake** y un **Data Warehouse**, permitiendo almacenar, procesar y analizar tanto datos estructurados como no estructurados en un solo entorno‚Äã.

üìå **Diferencias clave entre un Lakehouse y un Data Warehouse**

|**Caracter√≠stica**|**Lakehouse**|**Data Warehouse**|
|---|---|---|
|**Tipo de datos**|Estructurados, semiestructurados y no estructurados.|Solo datos estructurados.|
|**Almacenamiento**|Basado en **OneLake** con formato **Delta Lake**.|Bases de datos relacionales con ACID completo.|
|**Procesamiento**|Compatible con **Spark, SQL y Pipelines de Data Factory**.|Optimizado para consultas SQL transaccionales.|
|**Flexibilidad**|Almacena archivos en diferentes formatos (Parquet, JSON, CSV).|Depende de modelos tabulares predefinidos.|
|**Costos**|Escalable seg√∫n el consumo, sin necesidad de hardware dedicado.|Costoso debido a infraestructura optimizada para rendimiento SQL.|

üìå **¬øCu√°ndo usar un Lakehouse?**  
‚úÖ **Cuando se manejan datos diversos** (logs, sensores IoT, im√°genes, documentos y datos tabulares).  
‚úÖ **Si se requiere alta escalabilidad y flexibilidad** sin necesidad de una estructura r√≠gida.  
‚úÖ **Cuando se desea combinar Spark con SQL** para an√°lisis avanzados‚Äã.

---

## **2. Implementaci√≥n pr√°ctica de un Lakehouse en Microsoft Fabric**

### üîπ **Pasos para crear un Lakehouse en Fabric**

1Ô∏è‚É£ **Acceder al entorno de Fabric**

- Ir a **Microsoft Fabric** ‚Üí **Data Engineering** ‚Üí **Nuevo Lakehouse**.
- Asignar un nombre y confirmar la creaci√≥n‚Äã.

2Ô∏è‚É£ **Cargar datos en OneLake**

`df = spark.read.format("csv").option("header", "true").load("onelake://empresa/datos_ventas/") df.write.format("delta").save("onelake://empresa/lakehouse/ventas/")`

üìå **Explicaci√≥n:**

- Se ingestan datos en formato CSV.
- Se convierten a **Delta Lake** para mayor eficiencia.

3Ô∏è‚É£ **Consulta de datos en SQL Analytics Endpoint**

`SELECT categoria, SUM(ventas) AS total_ventas FROM lakehouse.ventas GROUP BY categoria;`

üìå **Permite a analistas y usuarios SQL acceder a los datos directamente**‚Äã

4Ô∏è‚É£ **Visualizaci√≥n en Power BI con Direct Lake**

- Conectar Power BI con el **SQL Analytics Endpoint del Lakehouse**.
- Crear dashboards interactivos en tiempo real‚Äã.

### üîπ **Ficheros y Tablas**

Dentro de un lakehouse, tenemos dos √°reas diferenciadas de almacenamiento, la de Ficheros y la tablas. El √°rea de **ficheros**, est√° destinada fundamentalmente a actuar como zona de aterrizaje (landing) de los datos, y para alojar datos no estructurados, como pueden ser im√°genes, dentro de nuestro lakehouse. La funcionalidad de accesos directos, ya comentada, proporciona una capa de "virtualizaci√≥n" que intenta minimizar el movimeinto de datos, posibilitando el acceso entre diferentes or√≠genes, incluso entre diferentes proveedores de nube p√∫blica. 

Por lo que respecta al √°rea de **tablas**, su funci√≥n es la de proporcionarnos una experiencia warehouse, sobre los datos que tenemos almacenados en nuestro onelake, siempre en formato Delta. Podemos crear b√°sicamente tres tipos diferenciados de tablas dentro de este √°rea: tablas administradas, tablas externas, y accesos directos de tabla

#### **Tablas administradas**
Son aquellas tablas de las que el motor Spark del lakehouse se encarga de gestionar y mantener, tanto en esquema como en datos. Son el tipo de tabla determinado, y el que proporciona toda la funcionalidad a nuestro lakehouse de control y mantenimiento de los datos. 

#### **Tablas externas**
Se conocen tambi√©n como tablas externas, y en este caso, la tabla no es m√°s que una definici√≥n de un esquema, que apunta a una ubicaci√≥n externa. El esquema se fuerza √∫nicamente en el momento de consulta de esa tabla. 
Nos puede ser √∫til, fundamentalmente en la capa silver, en escenarios en los que el esquema de los datos de origen, es susceptible de cambiar con frecuencia.

#### **Accesos directos de tabla**

Adem√°s de poder crear shortcuts a almacenamientos de ficheros en el √°rea **Files**  de un lakehouse, tambi√©n podemos crear estos accesos directos a tablas externas, lo que nos permitir√° poder acceder a esas tablas desde el SQL Endpoint, como si estuviesen realmente almacenadas en ese √≠tem de lakehouse. 
Si pensamos en nuestra arquitectura medall√≥n, y en el paso entre capas, los shortcuts nos pueden servir para, por ejemplo, referenciar tablas que no necesitamos modificar en el paso entre capas, evitando as√≠ tener que copiar y duplicar esas tablas entre las diferentes capas.  

---
## **3. El SQL Analytics Endpoint

### üîπ**Consultando con SQL el lakehouse**

El **punto de conexi√≥n de an√°lisis SQL** en Microsoft Fabric ofrece una experiencia basada en SQL para interactuar con las tablas Delta dentro de un almac√©n de lago (_lakehouse_). A continuaci√≥n, se detallan sus caracter√≠sticas principales:

- **Creaci√≥n autom√°tica**: Al generar un almac√©n de lago, se crea autom√°ticamente un punto de conexi√≥n de an√°lisis SQL que apunta al almacenamiento de tablas Delta del mismo.    
- **Modo de solo lectura**: Este punto de conexi√≥n permite √∫nicamente operaciones de lectura sobre las tablas Delta. Para modificar los datos, es necesario cambiar al modo de almac√©n de lago y utilizar Apache Spark.
- **Flexibilidad en la gesti√≥n de datos**: Aunque las operaciones de escritura no est√°n permitidas, se pueden crear funciones, definir vistas e implementar seguridad a nivel de objeto en SQL para estructurar y gestionar el acceso a los datos de manera efectiva.
- **Control de acceso mediante seguridad SQL**: Es posible establecer reglas de seguridad a nivel de objeto que se aplican al acceder a los datos a trav√©s del punto de conexi√≥n de an√°lisis SQL. Para garantizar que los datos no sean accesibles por otros medios, se deben configurar los roles y permisos adecuados en el √°rea de trabajo.
- **Reaprovisionamiento del punto de conexi√≥n**: Si el aprovisionamiento inicial falla, se ofrece la opci√≥n de reintentar directamente desde el almac√©n de lago, evitando la necesidad de crear uno nuevo.
- **Limitaciones actuales**: Las tablas Delta externas creadas con c√≥digo Spark no son visibles para el punto de conexi√≥n de an√°lisis SQL. 

Resumiendo, el punto de conexi√≥n de an√°lisis SQL en Microsoft Fabric facilita el an√°lisis y la gesti√≥n de datos en lakehouses mediante T-SQL, proporcionando una integraci√≥n fluida y herramientas robustas para el control de acceso y la estructuraci√≥n de datos.


--- 

## **4. Gobernanza y seguridad: Configuraci√≥n de accesos y permisos**

### üîπ **Esquemas en un lakehouse**

Microsoft Fabric Lakehouse admite la creaci√≥n de esquemas personalizados, lo que permite agrupar tablas para mejorar la detecci√≥n de datos, el control de acceso y la organizaci√≥n. Al crear un nuevo lakehouse, es posible habilitar esta funci√≥n seleccionando la opci√≥n "Esquemas de lakehouse (versi√≥n preliminar p√∫blica)". Una vez creado, nos encontraremos un esquema predeterminado llamado "dbo" bajo la secci√≥n de Tablas, el cual es permanente y no puede ser modificado o eliminado. 

Para almacenar una tabla en un esquema espec√≠fico, es necesario especificar el nombre del esquema al guardar la tabla. Si no se indica, la tabla se ubicar√° en el esquema predeterminado "dbo". Por ejemplo, utilizando PySpark, se podemos guardar una tabla en el esquema "ventas" con el siguiente comando:

`df.write.mode("Overwrite").saveAsTable("ventas.nombre_tabla")`

Adem√°s, el **Explorador** de Lakehouse permite organizar las tablas mediante la funci√≥n de arrastrar y soltar, facilitando su reubicaci√≥n entre diferentes esquemas. Es importante tener en cuenta que, al modificar una tabla, tambi√©n se deben actualizar los elementos relacionados, como el c√≥digo en cuadernos o los flujos de datos, para asegurar que est√©n alineados con el esquema correcto. Obviamente estas tareas no se realizan autom√°ticamente. 

- Para **referenciar m√∫ltiples tablas Delta** desde otro lakehouse de Fabric o desde un almacenamiento externo, se puede utilizar un acceso directo de esquema. Este acceso muestra todas las tablas bajo el esquema o carpeta seleccionados, reflejando cualquier cambio realizado en las tablas de la ubicaci√≥n de origen. 

- En el contexto de la elaboraci√≥n de informes con **Power BI**, al crear un modelo sem√°ntico, es posible seleccionar tablas de diferentes esquemas. Si existen tablas con el mismo nombre en distintos esquemas, se mostrar√°n n√∫meros junto a los nombres de las tablas en la vista de modelo para diferenciarlas.

- Al trabajar con **cuadernos** en un lakehouse que tiene habilitados los esquemas, las tablas se organizan seg√∫n sus respectivos esquemas en el explorador de objetos del cuaderno. Es posible arrastrar y soltar una tabla en una celda de c√≥digo para obtener un fragmento de c√≥digo que hace referencia al esquema correspondiente. La nomenclatura para referenciar una tabla sigue el formato: "√°rea_de_trabajo.lakehouse.esquema.tabla". Si se omite alg√∫n elemento, el ejecutor utilizar√° la configuraci√≥n predeterminada; por ejemplo, si solo se proporciona el nombre de la tabla, se asumir√° el esquema "dbo" del lakehouse predeterminado para el cuaderno.
- Para realizar **consultas SQL de Spark** que involucren m√∫ltiples √°reas de trabajo, se utiliza la nomenclatura "√°rea_de_trabajo.lakehouse.esquema.tabla" al referenciar las tablas en el c√≥digo. Esto permite combinar tablas de diferentes √°reas de trabajo, siempre que el usuario que ejecuta el c√≥digo tenga los permisos necesarios para acceder a dichas tablas. Es fundamental asegurarse de que las tablas provengan de lakehouses con esquemas habilitados, ya que la combinaci√≥n de tablas de lakehouses sin esquemas habilitados no funcionar√°.


Actualmente (Febrero 2025), en la versi√≥n preliminar p√∫blica, existen algunas limitaciones. Por ejemplo, el uso del √°rea de trabajo en el espacio de nombres para lakehouses compartidos no funciona correctamente, y obtener el esquema para tablas administradas en formatos no Delta (como CSV) no est√° soportado. 

### üîπ **Modelo de seguridad en un Lakehouse**

üìå Microsoft Fabric permite la gesti√≥n de permisos en un **Lakehouse** mediante **roles y controles de acceso**‚Äã.

|**Rol**|**Permisos**|
|---|---|
|**Admin**|Acceso total, configuraci√≥n y eliminaci√≥n de Lakehouse.|
|**Member**|Lectura y escritura de datos, ejecuci√≥n de scripts.|
|**Contributor**|Creaci√≥n y modificaci√≥n de objetos, sin configuraci√≥n de seguridad.|
|**Viewer**|Solo lectura de datos desde SQL Analytics Endpoint.|
Estos permisos se establecen a nivel de workspace y se heredan en todos los items, tambi√©n los lakehouse. 
### üîπ **Implementaci√≥n de seguridad en Lakehouse**

Desde el punto de vista de acceso al lakehouse, como cualquier otro item del espacio de trabajo, tendr√°n acceso predeterminado los usuarios a los que hayamos dado acceso a trav√©s de los roles del espacio de trabajo. En el caso de los usuarios con el rol de visor, tendr√°n acceso al SQL EndPoint, pero no podr√°n acceder al item de lakehouse. Sin embargo, podemos compartir con un usuario el acceso al endpoint SQL de nuestro lakehouse, sin necesidad de darle permisos sobre ning√∫n otro item del espacio de trabajo. Esto lo realizamos desde la opci√≥n de compartir del lakehouse

![[Compartir acceso lakehouse.png]]
Una vez hemos configurado el acceso, podemos llegar a niveles m√°s granulares, controlando el acceso a las tablas, a trav√©s de los roles que veremos en el SQL Endpoint y la seguridad a nivel de columna y a nivel de fila, que configuramos a trav√©s de las pol√≠ticas de seguridad. 


1Ô∏è‚É£ **Definir accesos mediante RBAC (Role-Based Access Control)**

`GRANT SELECT ON lakehouse.ventas TO [grupo_finanzas];`

üìå **Restringe acceso solo a usuarios autorizados**‚Äã.

2Ô∏è‚É£ **Uso de Column-Level Security (CLS) y Row-Level Security (RLS)**

`CREATE SECURITY POLICY Ventas_Politica ADD FILTER PREDICATE usuario_region = USER() ON lakehouse.ventas;`

üìå **Permite restringir filas seg√∫n el usuario autenticado**‚Äã.

3Ô∏è‚É£ **Uso de Shortcuts en OneLake para compartir datos sin replicarlos**

`CREATE SHORTCUT ventas_region TO "onelake://empresa/lakehouse/ventas/"`

üìå **Facilita compartir datos con otros equipos sin duplicaciones**‚Äã.

Tenemos que asegurarnos tambi√©n, de que antes de todo esto, los usuarios tienen los permisos necesarios a nivel de almacenamiento de Onelake. Podemos ver la combinaci√≥n de opciones en este enlace de la documentaci√≥n [Seguridad RBAC y Onelake](https://learn.microsoft.com/es-es/fabric/onelake/security/data-access-control-model?wt.mc_id=MVP_329801 )

---

## **5. Mantenimiento de tablas**

Como ocurre en cualquier motor de datos, debemos de realizar labores de mantenimiento sobre nuestros datos. Disponemos de una opci√≥n a trav√©s del interfaz gr√°fico de mantenimiento de tablas que nos proporciona las funcionalidades m√≠nimas para realizar ese mantenimiento. 

![[Mantenimiento tablas lakehouse.png]]

La caracter√≠stica de mantenimiento de tablas nos ofrece tres operaciones.

- **Optimizaci√≥n**: consolida varios archivos Parquet peque√±os en archivos grandes. Las arquitecturas de big data y lakehouse, est√°n pensadas para trabajar con archivos de gran tama√±o. Tener archivos de tama√±o superior a 128 MB y, de forma √≥ptima, cerca de 1 GB, mejora la compresi√≥n y la distribuci√≥n de datos, en los nodos del cl√∫ster. Reduce la necesidad de examinar numerosos archivos peque√±os para realizar operaciones de lectura eficaces. Por lo tanto, se recomienda ejectura estrategias de optimizaci√≥n orientadas a reducir el n√∫mero de ficheros. 
- **Orden en V (V-order)**: aplica la ordenaci√≥n, la codificaci√≥n y la compresi√≥n optimizadas a los archivos Parquet delta para permitir operaciones de lectura r√°pidas en todos los motores de Fabric. Para m√°s detalle sobre el funcionamiento de esta optimizaci√≥n, podemos consultar este enlace de la documentaci√≥n oficial  [V-Order](https://learn.microsoft.com/es-es/fabric/data-engineering/delta-optimization-and-v-order?wt.mc_id=MVP_329801&tabs=sparksql) 
- **Vacuum**: quita los archivos antiguos a los que ya no hace referencia un registro de tabla de Delta. Los archivos deben ser m√°s antiguos que el umbral de retenci√≥n, y este es por defecto de siete d√≠as. Todas las tablas delta de OneLake tienen el mismo per√≠odo de retenci√≥n. El per√≠odo de retenci√≥n de archivos es el mismo independientemente del motor de proceso de Fabric que estemos utilizando. Este mantenimiento es importante para optimizar el costo de almacenamiento. Establecer un per√≠odo de retenci√≥n m√°s corto afecta a las funcionalidades de viaje en el tiempo de Delta. 

---

## **6. Direct Lake**

**Direct Lake** es una opci√≥n de modo de almacenamiento para las tablas de un modelo sem√°ntico de Power BI almacenado en un √°rea de trabajo de Microsoft Fabric. Est√° optimizado para grandes vol√∫menes de datos que se pueden cargar r√°pidamente en la memoria desde tablas Delta, las cuales almacenan sus datos en archivos Parquet en **OneLake**, el repositorio unificado para todos los datos anal√≠ticos. Una vez cargados en memoria, el modelo sem√°ntico permite consultas de alto rendimiento, eliminando la necesidad de importar datos al modelo, lo que suele ser un proceso lento y costoso.

![[Direct lake.png]]

- **Carga R√°pida de Datos**: Permite la carga eficiente de grandes vol√∫menes de datos en memoria, facilitando an√°lisis m√°s r√°pidos.    
- **Actualizaciones Eficientes**: Las operaciones de actualizaci√≥n analizan los metadatos de las tablas Delta y actualizan el modelo para referenciar los archivos m√°s recientes en OneLake, reduciendo el tiempo y los recursos necesarios en comparaci√≥n con las actualizaciones tradicionales.    
- **Optimizaci√≥n de Recursos**: Al eliminar la necesidad de importar datos, se reduce el consumo de recursos de capacidad, como memoria y CPU.

Los modelos sem√°nticos en modo Direct Lake se conectan a tablas o vistas de un √∫nico lakehouse o warehouse en Fabric. Durante una operaci√≥n de actualizaci√≥n, el modelo analiza los metadatos de la versi√≥n m√°s reciente de las tablas Delta y se actualiza para referenciar los archivos m√°s recientes en OneLake. Este proceso, conocido como "operaci√≥n de enmarcado", es r√°pido y de bajo costo en comparaci√≥n con las actualizaciones tradicionales que implican la copia completa de los datos



--- 

## **7. Conclusi√≥n y Preguntas Clave**

‚úÖ **Un Lakehouse en Microsoft Fabric combina lo mejor de los Data Lakes y Data Warehouses.**  
‚úÖ **Se puede implementar r√°pidamente en OneLake y optimizar su rendimiento con Delta Lake.**  
‚úÖ **Los controles de seguridad y accesos permiten restringir y gestionar usuarios de manera eficiente.**

### **Preguntas para reflexi√≥n y discusi√≥n**

1Ô∏è‚É£ ¬øCu√°les son las ventajas de un **Lakehouse** sobre un **Data Warehouse** en mi empresa?  
2Ô∏è‚É£ ¬øC√≥mo se pueden aplicar **Row-Level Security** y **Column-Level Security** en Fabric?  
3Ô∏è‚É£ ¬øCu√°ndo usar **Power BI con Direct Lake** en vez de otros modelos de conexi√≥n?