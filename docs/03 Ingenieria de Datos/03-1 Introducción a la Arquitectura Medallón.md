# **Introducci√≥n a la Arquitectura Medall√≥n**

La **arquitectura Medall√≥n** es un enfoque de dise√±o de datos en lagos de datos (**Data Lakes**) que organiza la informaci√≥n en **tres capas o zonas** para garantizar calidad, gobernanza y eficiencia en el an√°lisis. Su objetivo es estructurar los datos desde su ingesti√≥n hasta su consumo, asegurando integridad y optimizaci√≥n en la consulta y transformaci√≥n.

Microsoft Fabric, con **OneLake** como n√∫cleo central, permite la implementaci√≥n de esta arquitectura de manera **nativa**, proporcionando una soluci√≥n unificada para la gesti√≥n de datos empresariales.
## **1. Concepto de Bronce, Plata y Oro: Estructura de capas en la gesti√≥n de datos**

### üîπ **¬øQu√© es la Arquitectura Medall√≥n?**

La **Arquitectura Medall√≥n** es un enfoque de gesti√≥n de datos en capas que mejora la calidad y accesibilidad de los datos almacenados en un **Data Lake** o **Lakehouse**. En Microsoft Fabric, esta arquitectura se implementa en **OneLake**, permitiendo gestionar la evoluci√≥n de los datos desde su ingesta hasta su consumo‚Äã. Existen diferentes nomenclaturas para denominar a las capas (bronze, silver, gold ; raw, validated, curated,...) en la documentaci√≥n oficial de Onelake, Microsoft opta por bronze, silver, gold, as√≠ que esa utilizaremos durante este curso. 

![Arquitectura Medall√≥n](<imagenes/Arquitectura Medall√≥n.png>)

### üîπ **Capas de la Arquitectura Medall√≥n**

#### **Capa Bronze**

**Prop√≥sito:** Almacenar los datos en su formato original tal y como llegan desde las fuentes.

üìå **Caracter√≠sticas:**

- Datos sin procesar, extra√≠dos directamente de fuentes transaccionales, archivos, APIs, sensores IoT, etc.
- **Formato:** JSON, CSV, Parquet, Avro, Delta Lake.
- **Gobernanza m√≠nima**, solo controles de acceso.
- **Ejemplo en Fabric:** Ingesta con **Data Factory** y almacenamiento en **OneLake**.

#### **Capa Plata(Validada)**

üìå **Prop√≥sito:** Refinar y limpiar los datos para hacerlos √∫tiles en an√°lisis.

üìå **Caracter√≠sticas:**

- Se eliminan valores nulos, se corrigen errores y se filtran registros.
- Se generan particiones y optimizaciones para mejorar rendimiento.
- Se aplican **modelos de gobernanza y seguridad**.

üìå **Ejemplo en Fabric:** Aplicaci√≥n de transformaciones en **Data Engineering** y almacenamiento en Delta Lake sobre **OneLake**.

#### **Capa Oro(Curada)**

üìå **Prop√≥sito:** Servir datos listos para an√°lisis y modelos de negocio.

üìå **Caracter√≠sticas:**

- Datos enriquecidos, agregados y optimizados.
- Indexaci√≥n para consultas eficientes.
- Modelado **dimensional (star schema)** para integraci√≥n con BI.

üìå **Ejemplo en Fabric:**

- Uso de **Data Warehouse** en Fabric para modelado relacional.
- Creaci√≥n de vistas optimizadas para **Power BI**.

|**Capa**|**Prop√≥sito**|**Ejemplo de uso**|
|---|---|---|
|**Bronce (Raw Layer)**|Almacena los datos sin procesar, tal como llegan desde las fuentes.|Datos de sensores IoT o logs de transacciones sin transformaci√≥n.|
|**Plata (Clean Layer)**|Se aplican procesos de limpieza, transformaci√≥n y deduplicaci√≥n.|Eliminaci√≥n de valores nulos y normalizaci√≥n de datos.|
|**Oro (Curated Layer)**|Datos listos para el consumo empresarial, optimizados para BI y anal√≠tica.|Tablas agregadas para informes financieros en Power BI.|

üìå **Beneficio clave:** Permite manejar datos **a gran escala**, asegurando que las transformaciones se realicen de manera eficiente y escalable en Fabric‚Äã.

---

## **2. Estrategias para mover datos entre capas y asegurar la calidad**

### üîπ **Proceso ELT en la Arquitectura Medall√≥n**

Cada capa tiene un conjunto de transformaciones clave que garantizan la **calidad y gobernanza de los datos** en Fabric.

üîπ **Estrategias para mover datos entre capas:**

1Ô∏è‚É£ **De Bronce a Plata:**  
‚úÖ **Filtrado de datos err√≥neos o duplicados**.(de-duplicaci√≥n)  
‚úÖ **Conversi√≥n de formatos** (JSON ‚Üí Parquet, CSV ‚Üí Delta Lake).  
‚úÖ **Enriquecimiento con datos de otras fuentes**.

2Ô∏è‚É£ **De Plata a Oro:**  
‚úÖ **Agregaciones y c√°lculos avanzados** para optimizar consultas.  
‚úÖ **Creaci√≥n de vistas optimizadas** en un Data Warehouse.  
‚úÖ **Indexaci√≥n y particionamiento** para mejorar el rendimiento‚Äã.

üìå **Ejemplo pr√°ctico:** Un pipeline de Data Factory puede extraer datos brutos de sensores (Bronce), limpiarlos y calcular promedios por hora (Plata), y finalmente generar reportes con tendencias de uso (Oro).

---

### üîπ **Patrones de despliegue**

Para implementar la arquitectura medallion en Fabric, podemos usar lakehouses (uno para cada zona), un datawarehouse o una combinaci√≥n de ambos. La decisi√≥n depender√° de nuestras preferencias y de la experiencia de su equipo. Fabric no ofrece flexibilidad: podemos usar diferentes motores anal√≠ticos que trabajan con una √∫nica copia de los datos en OneLake.

Aqu√≠ hay dos patrones que podemos considerar:

üîπ **Patr√≥n 1**: Crear cada zona como un lakehouse. En este caso, los usuarios empresariales acceden a los datos a trav√©s del punto de conexi√≥n de an√°lisis SQL.

üîπ **Patr√≥n 2**: Configurar las zonas de bronce y plata como lakehouse y la zona oro como datawarehouse. Aqu√≠, los usuarios empresariales acceden a los datos mediante el punto de conexi√≥n de almacenamiento de datos.

Aunque podemos crear todos los almacenes de lago dentro de una √∫nica √°rea de trabajo en Fabric, lo recomendable es que cada almac√©n tenga su propia √°rea de trabajo independiente. Este enfoque nos da m√°s control y mejor gobernanza a nivel de zona.

Para la **zona bronce**, lo ideal es almacenar los datos en su formato original o usar Parquet o Delta Lake. Siempre que sea posible, debemos de mantener los datos en su formato original. Si los datos de origen provienen de OneLake, Azure Data Lake Store Gen2 (ADLS Gen2), Amazon S3 o Google, es mejor crear un acceso directo en la zona bronce en lugar de copiarlos.

Para las **zonas plata y oro**, se recomienda usar tablas Delta por las funcionalidades adicionales y mejoras de rendimiento que ofrecen. Fabric normaliza el formato Delta Lake y, por defecto, cada motor de Fabric escribe los datos en este formato. Adem√°s, estos motores aplican la optimizaci√≥n en tiempo de escritura **V-Order** al formato de archivo Parquet, lo que permite lecturas extremadamente r√°pidas para motores como Power BI, SQL, Apache Spark y otros. 


--- 

## **3. Delta lakehouse**

### üîπ **Apache Parquet**

**Parquet** es un formato de¬†almacenamiento columnar¬†de c√≥digo abierto que se cre√≥ como parte de Apache Hadoop y que actualmente se utiliza en muchos otros sistemas.
Su principal caracter√≠stica es que organiza los datos en columnas, a diferencia de otros formatos que los organizan en filas, como CSV. Adem√°s, a cada columna se le asigna un tipo de dato. Esto tiene varias ventajas, entre ellas quiero resaltar las dos que me parecen m√°s importantes.
La primera ventaja es la¬†reducci√≥n del espacio de almacenamiento, ya que los datos de cada columna se pueden codificar de manera independiente, con un algoritmo espec√≠fico para el tipo de dato de la columna. Por ejemplo, para una columna con textos donde los valores se repitan mucho, en lugar de almacenar directamente el texto de cada fila, se puede crear primero un diccionario con los valores √∫nicos y luego para cada fila almacenar un valor num√©rico con el √≠ndice al diccionario. De esta forma se logra reducir el espacio requerido para almacenar la columna. Parquet soporta varios m√©todos de codificaci√≥n.
Adem√°s de esta codificaci√≥n, Parquet tambi√©n soporta varios tipos de compresi√≥n, como **Snappy** o GZIP, con lo cu√°l se logra reducir a√∫n m√°s el espacio de almacenamiento.
Para dar una idea de cuanto se comprimen los datos, he convertido un archivo CSV con 11 millones de filas a Parquet. El tama√±o en disco del CSV es de unos 500 MB mientras que el tama√±o del archivo Parquet es de unos 42 MB.
Por lo tanto,¬†con los archivos Parquet podemos reducir los costes de almacenamiento, sobre todo si estamos usando almacenamiento en la nube como es el caso de **Onelake**.
La segunda ventaja es que¬†las columnas se pueden leer de manera independiente, o sea, si s√≥lo se quieren obtener los datos de algunas columnas, estos se pueden ir a buscar directamente, sin necesidad de cargar los datos de las columnas restantes. 

Otras dos caracter√≠sticas muy importantes de Parquet son:

- **Metadatos**: adem√°s de los datos, guarda informaci√≥n sobre los nombres y los tipos de las columnas, estad√≠sticas de los datos, entre otras cosas.
- **Estructuras anidadas**: es capaz de representar datos con una estructura compleja, por ejemplo, que una columna contenga a su vez otra tabla.

Se convirti√≥ r√°pidamente en el formato de referencia en el paradigma Big Data, por la compresi√≥n que ayudaba a reducir costes, por poder manejar gran cantidad de datos y estar orientado al an√°lisis, y por facilitar los patrones de ELT, con una estructura de metadata integrada. 

---

### üîπ **¬øQu√© es un Delta lake?**

Delta Lake es una capa de almacenamiento open source que ofrece transacciones ACID (atomicidad, coherencia, aislamiento y durabilidad) para cargas de trabajo de macrodatos de Apache Spark. Est√° basado en una evoluci√≥n del formato Apache Parquet, denominada Delta, desarrollada por Databricks, que a d√≠a de hoy se ha convertido en un est√°ndar de facto en el mundo lakehouse, desde que Databricks decidi√≥ liberarlo como un proyecto Open Source tambi√©n.  Por lo tanto el **formato de fichero Delta** es un est√°ndar de almacenamiento optimizado basado en **Parquet**, dise√±ado para mejorar la eficiencia en la gesti√≥n de datos en lagos de datos y almacenes anal√≠ticos. Microsoft Fabric adopta **Delta Lake** como formato principal para almacenamiento en **OneLake**, asegurando compatibilidad con m√∫ltiples motores anal√≠ticos y soporte para transacciones ACID. A continuaci√≥n se detallas las principales caracter√≠sticas de este formato:

| Caracter√≠stica                                         | Descripci√≥n                                                                                                                                                                                                                                                                                                                |
| ------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Transacciones ACID**                                 | Los lakehouses suelen llenarse con m√∫ltiples procesos y canalizaciones, donde algunos escriben datos mientras otros los leen. Delta Lake  ofrece transacciones ACID para garantizar la integridad de los datos, evitando problemas en los registros. As√≠ podemos asegurarnos de que los datos sean consistentes y fiables. |
| **Control escalable de metadatos**                     | Administrar grandes vol√∫menes de datos puede ser complicado, pero Delta Lake maneja incluso los metadatos a gran escala. Aprovecha la potencia de Spark para procesarlos de manera distribuida, lo que permite gestionar datos en la escala de petabytes sin perder eficiencia.                                            |
| **Viaje en el tiempo (control de versiones de datos)** | ¬øNecesitas volver a una versi√≥n anterior de los datos? Con Delta Lake podemos "deshacer" cambios y recuperar versiones pasadas, lo que facilita auditor√≠as, an√°lisis de tendencias y recuperaci√≥n de informaci√≥n en caso de errores.                                                                                       |
| **Formato abierto**                                    | Delta Lake utiliza Apache Parquet como formato de referencia, lo que nos permite beneficiarse de esquemas de compresi√≥n y codificaci√≥n eficientes sin depender de formatos propietarios.                                                                                                                                   |
| **Lote unificado y origen/receptor de streaming**      | Las tablas en Delta Lake pueden funcionar tanto para procesamiento por lotes como en streaming. Podemos ingerir datos en tiempo real, reponer hist√≥ricos de manera sencilla y ejecutar consultas interactivas sin problemas.                                                                                               |
| **Aplicaci√≥n de esquemas**                             | Se aseguran de que los tipos de datos sean correctos y de que todas las columnas necesarias est√©n presentes. As√≠ evitan inconsistencias y mantienen la coherencia de los datos.                                                                                                                                            |
| **Evoluci√≥n del esquema**                              | Pueden realizar cambios en los esquemas de las tablas sin necesidad de escribir DDL de migraci√≥n manualmente. As√≠, la estructura de los datos se adapta autom√°ticamente a nuevas necesidades.                                                                                                                              |
| **Historial de auditor√≠as**                            | Delta Lake registra autom√°ticamente cada cambio en los datos, permiti√©ndoles realizar auditor√≠as completas y rastrear modificaciones de manera sencilla.                                                                                                                                                                   |
| **Actualizaciones y eliminaciones**                    | Pueden actualizar y eliminar datos f√°cilmente con operaciones como MERGE, UPDATE y DELETE, sin complicaciones y garantizando el cumplimiento de normativas.                                                                                                                                                                |
| **100% compatible con la API de Apache Spark**         | No necesitan hacer cambios en sus canalizaciones de datos actuales para usar Delta Lake, ya que es totalmente compatible con Spark.                                                                                                                                                                                        |

Uno de los mayores desaf√≠os en el almacenamiento de datos es garantizar que las consultas sean r√°pidas y eficientes. En el formato **Delta Lake**, existen dos estrategias clave para mejorar la ejecuci√≥n de consultas anal√≠ticas sobre grandes vol√∫menes de datos: **Z-Ordering** y **V-Ordering**. Ambas t√©cnicas optimizan la organizaci√≥n de los datos dentro de los archivos **Parquet**, reduciendo el tiempo de b√∫squeda y mejorando la latencia de las consultas.

---

#### **Z-Ordering**

**Z-Ordering** es una t√©cnica de **clustering** que mejora la eficiencia de las consultas al **reorganizar los datos dentro de los archivos Delta seg√∫n una columna clave**. Esta optimizaci√≥n es particularmente √∫til en escenarios donde las consultas filtran frecuentemente por una o varias columnas espec√≠ficas.

 üìå **¬øC√≥mo funciona?**

- Organiza los datos utilizando un **algoritmo de Morton (Z-order curve)**, que **agrupa valores similares dentro del mismo archivo**.
- Reduce **la cantidad de archivos que deben escanearse** en consultas con filtros en columnas clave.
- Mejora la **localidad de los datos**, facilitando la lectura secuencial en almacenamiento distribuido.

üëâ **Casos de uso √≥ptimos:**

- Tablas con **grandes vol√∫menes de datos** y **consultas que filtran por rangos en columnas espec√≠ficas**.
- Datos con **altos √≠ndices de cardinalidad**, donde la dispersi√≥n de valores en los archivos podr√≠a generar **lecturas innecesarias**.

---

#### **V-Ordering**

**V-Ordering** (Vertical Ordering) es un **m√©todo de ordenaci√≥n dentro de los archivos Parquet** que mejora el rendimiento de las consultas al **minimizar los costos de descompresi√≥n y escaneo**. La aplicaci√≥n de V-Ordering es autom√°tica cuando almacenamos datos en formato delta en Onelake. 

 üìå **¬øC√≥mo funciona?**

- Reordena los datos **dentro de cada archivo Parquet** en un patr√≥n de **valores agrupados y ordenados**.
- Optimiza la lectura de **columnas altamente repetitivas**, como dimensiones con pocos valores √∫nicos.
- Reduce el **tama√±o del archivo comprimido**, ya que los valores similares se agrupan de forma m√°s eficiente.

üëâ **Casos de uso √≥ptimos:**

- Datos con **alta repetici√≥n en columnas espec√≠ficas**, donde la organizaci√≥n de los valores mejora la compresi√≥n.
- Consultas con **agregaciones frecuentes**, ya que permite **lecturas m√°s eficientes y menos I/O**.
---

## **4. Conclusi√≥n y Preguntas Clave**

‚úÖ **La Arquitectura Medall√≥n mejora la calidad y estructuraci√≥n de los datos en Fabric.**  
‚úÖ **Cada capa (Bronce, Plata y Oro) tiene un prop√≥sito espec√≠fico para la gesti√≥n de datos.**  
‚úÖ **Fabric proporciona herramientas para mover datos entre capas de manera eficiente con Spark y Data Factory.**

### **Preguntas para reflexi√≥n y discusi√≥n**

1Ô∏è‚É£ ¬øC√≥mo puedo asegurar la gobernanza y calidad de los datos en cada capa?  
2Ô∏è‚É£ ¬øCu√°ndo debo utilizar un Data Warehouse en vez de un Lakehouse para la capa Oro?  
3Ô∏è‚É£ ¬øQu√© impacto tiene la arquitectura Medall√≥n en el rendimiento de las consultas en Fabric?